{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing and cleaning"
      ],
      "metadata": {
        "id": "WtoM6t98KC4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to clean information on google colab"
      ],
      "metadata": {
        "id": "8mzdxWB2Prwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 0) Setup: Mount Drive and Install Packages ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install openpyxl tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === 1) Base directory and files ===\n",
        "BASE_DIR = Path('/content/drive/MyDrive/nytimes/data_edited')\n",
        "FILES = [\n",
        "    'February-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'March-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'April-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'May-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'June-2025-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'July-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'August-2025-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'September-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'October-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "    'November-2025-Voter-Omnibus-Crosstabs-Edited.xlsx',\n",
        "]\n",
        "\n",
        "# === 2) Map filenames → YYYY-MM ===\n",
        "month_map = {\n",
        "    'February': '2025-02', 'March': '2025-03', 'April': '2025-04', 'May': '2025-05', 'June': '2025-06',\n",
        "    'July': '2025-07', 'August': '2025-08', 'September': '2025-09', 'October': '2025-10', 'November': '2025-11'\n",
        "}\n",
        "\n",
        "def parse_month_from_filename(fn: str) -> str:\n",
        "    for name, ym in month_map.items():\n",
        "        if name in fn:\n",
        "            return ym\n",
        "    return 'unknown'\n",
        "\n",
        "# === 3) Tidy function for one sheet ===\n",
        "def tidy_one_sheet(df: pd.DataFrame, period: str, sheet_name: str, skipped_log: list):\n",
        "    if df.shape[1] < 3:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Header rows: first two rows\n",
        "    header_rows = df.iloc[0:2, :].copy()\n",
        "    data = df.iloc[2:, :].dropna(how='all')  # Remove empty rows\n",
        "\n",
        "    # Build MultiIndex for columns\n",
        "    cols = []\n",
        "    for j in range(df.shape[1]):\n",
        "        if j == 0:\n",
        "            cols.append(('__meta__', 'question'))\n",
        "        elif j == 1:\n",
        "            cols.append(('__meta__', 'response_option'))\n",
        "        else:\n",
        "            cat = str(header_rows.iat[0, j]).strip() if pd.notna(header_rows.iat[0, j]) else ''\n",
        "            sub = str(header_rows.iat[1, j]).strip() if pd.notna(header_rows.iat[1, j]) else ''\n",
        "            cols.append((cat, sub))\n",
        "\n",
        "    data.columns = pd.MultiIndex.from_tuples(cols)\n",
        "\n",
        "    # Extract meta columns\n",
        "    meta = data['__meta__'].copy()\n",
        "    meta.columns = ['question', 'response_option']\n",
        "\n",
        "    # Drop rows where both question and response_option are NaN\n",
        "    data = data.loc[~(meta['question'].isna() & meta['response_option'].isna())].copy()\n",
        "\n",
        "    # Forward-fill question text\n",
        "    qcol = meta['question'].ffill()\n",
        "\n",
        "    # Split question into ID and text\n",
        "    def split_q(x):\n",
        "        if pd.isna(x): return (None, None)\n",
        "        m = re.match(r\"\\s*\\[(?P<qid>[^\\]]+)\\]\\s*(?P<qtext>.*)$\", str(x).strip())\n",
        "        if m: return (m.group('qid'), m.group('qtext'))\n",
        "        return (None, str(x))\n",
        "\n",
        "    qid, qtext = zip(*qcol.map(split_q))\n",
        "\n",
        "    # Stack demographic columns\n",
        "    long_frames = []\n",
        "    for (cat, sub) in data.columns:\n",
        "        if cat == '__meta__':\n",
        "            continue\n",
        "        values = data[(cat, sub)].values\n",
        "        if all(pd.isna(values)):  # If all values are NaN, log and skip\n",
        "            skipped_log.append(f\"Skipped block: Question '{qid[0]}' ({sheet_name}, {period}) for {cat}/{sub}\")\n",
        "            continue\n",
        "        block = pd.DataFrame({\n",
        "            'period': period,\n",
        "            'sheet': sheet_name,\n",
        "            'question_id': qid,\n",
        "            'question_text': qtext,\n",
        "            'response_option': meta['response_option'].values,\n",
        "            'demo_category': cat,\n",
        "            'demo_subcategory': sub,\n",
        "            'value': values,\n",
        "        })\n",
        "        long_frames.append(block)\n",
        "\n",
        "    out = pd.concat(long_frames, ignore_index=True) if long_frames else pd.DataFrame()\n",
        "\n",
        "    # Convert to numeric\n",
        "    def to_num(v):\n",
        "        if pd.isna(v): return pd.NA\n",
        "        s = str(v).strip()\n",
        "        if s == '': return pd.NA\n",
        "        s = s.replace(',', '')\n",
        "        if s.endswith('%'):\n",
        "            try: return float(s[:-1]) / 100.0\n",
        "            except: return pd.NA\n",
        "        try: return float(s)\n",
        "        except: return pd.NA\n",
        "\n",
        "    out['value_num'] = out['value'].map(to_num)\n",
        "    return out\n",
        "\n",
        "# === 4) Loop all files/sheets with progress bar ===\n",
        "all_long, notes, skipped_log = [], [], []\n",
        "for fn in tqdm(FILES, desc=\"Processing files\"):\n",
        "    fp = BASE_DIR / fn\n",
        "    if not fp.exists():\n",
        "        notes.append(f\"Missing file {fn}\")\n",
        "        continue\n",
        "    period = parse_month_from_filename(fn)\n",
        "    try:\n",
        "        xls = pd.ExcelFile(fp, engine='openpyxl')\n",
        "        for sheet in xls.sheet_names:\n",
        "            try:\n",
        "                df = xls.parse(sheet_name=sheet, header=None)\n",
        "                tidy = tidy_one_sheet(df, period, sheet, skipped_log)\n",
        "                if not tidy.empty:\n",
        "                    all_long.append(tidy)\n",
        "            except Exception as e:\n",
        "                notes.append(f\"Error parsing sheet '{sheet}' in {fn}: {e}\")\n",
        "    except Exception as e:\n",
        "        notes.append(f\"Error opening {fn}: {e}\")\n",
        "\n",
        "# === 5) Concatenate & normalize response labels ===\n",
        "if all_long:\n",
        "    long_df = pd.concat(all_long, ignore_index=True)\n",
        "\n",
        "    def norm_resp(s):\n",
        "        if pd.isna(s): return s\n",
        "        t = str(s).strip().lower()\n",
        "        rep = {\n",
        "            'rigth direction': 'right direction',\n",
        "            'right direction': 'right direction',\n",
        "            'wrong track': 'wrong track',\n",
        "            'unsure': 'unsure',\n",
        "            'dk': 'unsure',\n",
        "            \"don't know\": 'unsure',\n",
        "            'don’t know': 'unsure',\n",
        "            'refused': 'unsure'\n",
        "        }\n",
        "        return rep.get(t, t)\n",
        "\n",
        "    long_df['response_option_norm'] = long_df['response_option'].map(norm_resp)\n",
        "\n",
        "    # Save outputs in Drive\n",
        "    tidy_path = BASE_DIR / 'polls_2025_long_tidy.csv'\n",
        "    codebook_path = BASE_DIR / 'polls_codebook_2025.csv'\n",
        "\n",
        "    long_df.to_csv(tidy_path, index=False)\n",
        "    codebook = (long_df.dropna(subset=['question_id', 'question_text'])\n",
        "                        .drop_duplicates(['question_id','question_text'])\n",
        "                        .sort_values('question_id'))\n",
        "    codebook.to_csv(codebook_path, index=False)\n",
        "\n",
        "    print(f\"\\n✅ Tidy data saved to: {tidy_path}\")\n",
        "    print(f\"✅ Codebook saved to: {codebook_path}\")\n",
        "    print({\n",
        "        'rows': len(long_df),\n",
        "        'unique_questions': long_df['question_id'].nunique(),\n",
        "        'periods': sorted(long_df['period'].dropna().unique().tolist())[:12],\n",
        "        'demo_categories_examples': long_df['demo_category'].dropna().unique().tolist()[:10]\n",
        "    })\n",
        "else:\n",
        "    print({'rows': 0, 'note': 'No rows produced; check file format and sheet structure.'})\n",
        "\n",
        "print(\"\\nNotes:\")\n",
        "print(notes)\n",
        "\n",
        "print(\"\\nSkipped blocks (empty data):\")\n",
        "for s in skipped_log[:20]:  # Show first 20\n",
        "    print(s)\n",
        "print(f\"... Total skipped: {len(skipped_log)}\")"
      ],
      "metadata": {
        "id": "bzDjKquwKCPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}